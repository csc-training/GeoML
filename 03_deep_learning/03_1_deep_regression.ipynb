{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**TODO:**\n",
    "* check all texts\n",
    "* fix comments\n",
    "* have it without outputs on Github\n",
    "* compare to results from shallow models\n",
    "* add task to build deeper models, add shape consinderations! Links to relevant pages.\n",
    "* more description to model building\n",
    "* reminder on parameters \n",
    "* train/test/val, validation from test dataset\n",
    "* make some tuning a task\n",
    "* Add note on train/test/validation and CV\n",
    "* point paths to correct places, absolute paths\n",
    "* explain numbers in model generation\n",
    "* talk about engineered features\n",
    "* make sure to make it possible to go through this in 1:00\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Regression\n",
    "\n",
    "Data - prepared vector data\n",
    "\n",
    "Goal - use deep learning for predict the median income from zip code level population and spatial variables, assess the model accuracy with a test dataset, predicts the number to all zip codes and writes it to a geopackage\n",
    "\n",
    "Content of this notebook:\n",
    "\n",
    "0. Prepare environment\n",
    "1. Set paths\n",
    "2. Check for GPU\n",
    "3. Reading and preparing data \n",
    "4. Model definition\n",
    "5. Prediction and inference\n",
    "6. Comparison to shallow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from math import sqrt\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = {os.environ.get('USER')}\n",
    "base_directory= f'/scratch/project_2002044/{username}/GeoML'\n",
    "preprocessed_data_location = os.path.join(base_directory,'preprocessed_data')\n",
    "dataset_name = 'paavo' # to be changed to vector!\n",
    "\n",
    "train_dataset_name = os.path.join(preprocessed_data_location,dataset_name,'train_zip_code_data.gpkg')\n",
    "test_dataset_name = os.path.join(preprocessed_data_location,dataset_name,'test_zip_code_data.gpkg')\n",
    "train_label_name = os.path.join(preprocessed_data_location,dataset_name,'train_income_labels.pkl')\n",
    "test_label_name = os.path.join(preprocessed_data_location,dataset_name,'test_income_labels.pkl')\n",
    "\n",
    "\n",
    "### Relative path to the zip code geopackage file that was prepared by vectorDataPreparations.py\n",
    "input_geopackage_path = os.path.join(preprocessed_data_location,dataset_name,\"zip_code_data_after_preparation.gpkg\")\n",
    "\n",
    "\n",
    "results_location = '../results'\n",
    "metrics_filename = os.path.join(results_location,dataset_name,'shallow_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGPUavailability():\n",
    "    device = tensorflow.config.list_physical_devices('GPU')\n",
    "    if device:\n",
    "        print(\"We have a GPU available!\")\n",
    "    else:\n",
    "        print(\"Sadly no GPU available. :( you have settle with a CPU. Good luck!\")\n",
    "\n",
    "checkGPUavailability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reading and preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and test datasets\n",
    "x_train = gpd.read_file(train_dataset_name)\n",
    "x_test = gpd.read_file(test_dataset_name)\n",
    "y_train = pd.read_pickle(train_label_name)\n",
    "y_test = pd.read_pickle(test_label_name)\n",
    "num_of_x_columns =  x_train.to_numpy().shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deep learning tasks we will need one more dataset. One dataset it for training (`train`), another dataset for hyperparameter tuning (`evaluation`) and the last one is the unseen dataset (`test`) to finally test how well the model performs on previously unseen data. As we have used the training dataset for scaling, we cannot split it off the training dataset, so we split it from the original `test` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_test, y_test, test_size=.5, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first layer with 64 perceptrons. Activation function is relu\n",
    "model.add(Dense(64, activation='relu', input_shape=(num_of_x_columns,)))\n",
    "\n",
    "# Add another layer with 64 perceptrons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# The last layer has to have only 1 perceptron as it is the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Setting optimizer and loss functions. Learning rate set to 0.001\n",
    "model.compile(optimizer=RMSprop(learning_rate=.001), loss='mse', metrics=['mae','mse'])\n",
    "print(model.summary())\n",
    "\n",
    "#Train the network with 1000 epochs and batch size of 64\n",
    "model.fit(x_train, y_train, epochs=1000, shuffle=True, batch_size=64, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the performance of the model using test data\n",
    "prediction = model.predict(x_test)\n",
    "r2 = r2_score(y_test, prediction)\n",
    "rmse = sqrt(mean_squared_error(y_test, prediction))\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(\"\\nMODEL ACCURACY METRICS WITH TEST DATASET: \\n\" +\n",
    "        \"\\t Root mean squared error: \"+ str(rmse) + \"\\n\" +\n",
    "        \"\\t Mean absolute error: \" + str(mae) + \"\\n\" +\n",
    "        \"\\t Coefficient of determination: \" + str(r2) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison to shallow models and baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shallow_metrics = pd.read_csv(metrics_filename)\n",
    "\n",
    "print(shallow_metrics.sort_values(by=['RMSE'], ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
