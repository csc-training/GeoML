{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Regression\n",
    "\n",
    "Data - prepared vector data\n",
    "Goal - use deep learning for predict the median income from zip code level population and spatial variables, assess the model accuracy with a test dataset, predicts the number to all zip codes and writes it to a geopackage\n",
    "Content\n",
    "1. Load libraries\n",
    "2. Set paths\n",
    "3. Check for GPU\n",
    "4. Prep data\n",
    "5. Model definition\n",
    "6. Prediction\n",
    "7. Write results to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load all needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import geopandas as gpd\n",
    "from math import sqrt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FILL HERE the path to the data in Puhti\n",
    "data_folder = \"/scratch/project_2002044/data/GIS_ML_COURSE_DATA/data/paavo/\"\n",
    "\n",
    "### FILL HERE the path to YOUR working directory\n",
    "results_folder = \"/scratch/project_2002044/students/<YOUR-STUDENT-NUMBER>\"\n",
    "\n",
    "### Relative path to the zip code geopackage file that was prepared by vectorDataPreparations\n",
    "input_geopackage_path = os.path.join(data_folder,\"zip_code_data_after_preparation.gpkg\")\n",
    "output_geopackage_path = os.path.join(results_folder,\"median_income_per_zipcode_deep_learning.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGPUavailability():\n",
    "    device = tensorflow.test.is_gpu_available()\n",
    "    if device:\n",
    "        print(\"We have a GPU available!\")\n",
    "    else:\n",
    "        print(\"Sadly no GPU available. :( you have settle with a CPU. Good luck!\")\n",
    "\n",
    "checkGPUavailability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Prep data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_gdf = gpd.read_file(input_geopackage_path,encoding='utf-8')\n",
    "### Split the gdf to x (the predictor attributes) and y (the attribute to be predicted)\n",
    "y = original_gdf['hr_mtu'].to_numpy()  # median income\n",
    "\n",
    "### remove geometry, textual fields and the y field\n",
    "x = original_gdf.drop(['geometry', 'postinumer', 'nimi', 'hr_mtu'], axis=1).to_numpy()\n",
    "num_of_x_columns =  x.shape[1]\n",
    "\n",
    "### Split the both datasets to train (80%) and test (20%) datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize a Sequential keras model\n",
    "model = Sequential()\n",
    "\n",
    "### Add first layer with 64 perceptrons. Activation function is relu\n",
    "model.add(Dense(64, activation='relu', input_shape=(num_of_x_columns,)))\n",
    "\n",
    "### Add another layer with 64 perceptrons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "### The last layer has to have only 1 perceptron as it is the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "### Setting optimizer and loss functions. Learning rate set to 0.001\n",
    "model.compile(optimizer=RMSprop(lr=.001), loss='mse', metrics=['mae','mse'])\n",
    "print(model.summary())\n",
    "\n",
    "### Train the network with 1000 epochs and batch size of 64\n",
    "model.fit(x_train, y_train, epochs=1000, shuffle=True, batch_size=64, verbose=2)\n",
    "\n",
    "### Evaluating the performance of the model using test data\n",
    "prediction = model.predict(x_test)\n",
    "r2 = r2_score(y_test, prediction)\n",
    "rmse = sqrt(mean_squared_error(y_test, prediction))\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(\"\\nMODEL ACCURACY METRICS WITH TEST DATASET: \\n\" +\n",
    "        \"\\t Root mean squared error: \"+ str(rmse) + \"\\n\" +\n",
    "        \"\\t Mean absolute error: \" + str(mae) + \"\\n\" +\n",
    "        \"\\t Coefficient of determination: \" + str(r2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Drop the not-used columns from original_gdf as done before model training.\n",
    "x = original_gdf.drop(['geometry', 'postinumer', 'nimi', 'hr_mtu'], axis=1).to_numpy()\n",
    "\n",
    "### Predict the median income with the already trained model\n",
    "prediction = model.predict(x)\n",
    "\n",
    "### Join the predictions to the original geodataframe and pick only interesting columns for results\n",
    "original_gdf['predicted_hr_mtu'] = prediction.round(0)\n",
    "original_gdf['difference'] = original_gdf['predicted_hr_mtu'] - original_gdf['hr_mtu']\n",
    "\n",
    "resulting_gdf = original_gdf[['postinumer','nimi','hr_mtu','predicted_hr_mtu','difference','geometry']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulting_gdf.to_file(output_geopackage_path, driver=\"GPKG\")\n",
    "print(\"The predictions for all zip codes were written to: \" + output_geopackage_path + \"\\n\\nTHE END\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
