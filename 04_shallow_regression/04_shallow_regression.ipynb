{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* have it without outputs on Github\n",
    "* Keep or remove linear regression?\n",
    "* task update: remove all but RF, make task to also find other models, provide \"solution\" script with % load solutions.py (note that this cell has to be run twice then)\n",
    "* make sure to make it possible to go through in 30 min\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow regression for vector data\n",
    "\n",
    "Reminder: We are within supervised learning (we have labels/targets that are real values) -> Regression\n",
    "\n",
    "Data and goal: In this notebook we read the zip code data produced by **02_vector_preparations** and create different machine learning models for\n",
    "predicting the average zip code income from population and spatial features. We will adjust parameters to improve the performance on a validation dataset and finally assesses the models error metrics with a test dataset.\n",
    "\n",
    "Notebook contents:\n",
    "\n",
    "0. Environment preparation\n",
    "1. Reading the data\n",
    "2. Function defintion\n",
    "3. Baseline naive approach\n",
    "4. Baseline linear regression\n",
    "5. Gradient Boosting\n",
    "6. Random Forest\n",
    "7. Bagging\n",
    "8. AdaBoost\n",
    "9. Comparing the models\n",
    "10. Task \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "# machine learning models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor,ExtraTreesRegressor, AdaBoostRegressor\n",
    "# error metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the data\n",
    "### 1.1 Define input and output file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get('USER')\n",
    "base_directory= f'/scratch/project_2002044/{username}/2022/GeoML'\n",
    "\n",
    "# inputs, all datasets created in 02_vector_preparation.ipynb\n",
    "data_directory = os.path.join(base_directory,'data')\n",
    "preprocessed_data_directory = os.path.join(data_directory,'preprocessed_regression')\n",
    "scaled_train_dataset_name = os.path.join(preprocessed_data_directory,'scaled_train_zip_code_data.csv')\n",
    "scaled_test_dataset_name = os.path.join(preprocessed_data_directory,'scaled_test_zip_code_data.csv')\n",
    "scaled_val_dataset_name = os.path.join(preprocessed_data_directory,'scaled_val_zip_code_data.csv')\n",
    "train_label_name = os.path.join(preprocessed_data_directory,'train_income_labels.pkl')\n",
    "test_label_name = os.path.join(preprocessed_data_directory,'test_income_labels.pkl')\n",
    "val_label_name = os.path.join(preprocessed_data_directory,'val_income_labels.pkl')\n",
    "\n",
    "# read also unscaled datasets\n",
    "train_dataset_name = os.path.join(preprocessed_data_directory,'train_zip_code_data.csv')\n",
    "test_dataset_name = os.path.join(preprocessed_data_directory,'test_zip_code_data.csv')\n",
    "val_dataset_name = os.path.join(preprocessed_data_directory,'val_zip_code_data.csv')\n",
    "\n",
    "# outputs\n",
    "results_directory = os.path.join(data_directory,'regression_results')\n",
    "\n",
    "def create_dir(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "create_dir(results_directory)\n",
    "\n",
    "metrics_filename = os.path.join(results_directory,'shallow_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible results when randomness is involved, we can set a random seed\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train, validation and test datasets\n",
    "scaled_x_train = pd.read_csv(scaled_train_dataset_name)\n",
    "scaled_x_val = pd.read_csv(scaled_val_dataset_name)\n",
    "x_train = pd.read_csv(train_dataset_name)\n",
    "x_val = pd.read_csv(val_dataset_name)\n",
    "y_train = pd.read_pickle(train_label_name)\n",
    "y_val = pd.read_pickle(val_label_name)\n",
    "scaled_x_test = pd.read_csv(scaled_test_dataset_name)\n",
    "x_test = pd.read_csv(test_dataset_name)\n",
    "y_test = pd.read_pickle(test_label_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function definitions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating error metrics for regression predictions\n",
    "\n",
    "def calculate_error_metrics(test_labels,label_predictions, model_name):\n",
    "\n",
    "    #Asessing the performance of the model with root mean squared error, mean absolute error and coefficient of determination r2\n",
    "    rmse = sqrt(mean_squared_error(test_labels, label_predictions))\n",
    "    mae = mean_absolute_error(test_labels, label_predictions)\n",
    "    r2 = r2_score(test_labels, label_predictions)\n",
    "\n",
    "    # store them in a dictionary\n",
    "    metrics_dict = dict(zip(['model','RMSE','MAE','R2'],[model_name,rmse,mae,r2]))\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "def print_error_metrics(metrics_dict, model_name, dataset_name):\n",
    "    print(f\"\\nError metrics for {model_name} on the {dataset_name} dataset: \\n\" +\n",
    "            f\"\\t Root mean squared error (RMSE): {round(metrics_dict['RMSE'])} \\n\" +\n",
    "            f\"\\t Mean absolute error (MAE): {round(metrics_dict['MAE'])} \\n\" +\n",
    "            f\"\\t Coefficient of determination (R2): {round(metrics_dict['R2'],4)} \\n\")\n",
    "\n",
    "def store_error_metrics(test_labels, label_predictions, model_name, metrics_collection = None):\n",
    "\n",
    "    metrics_dict = calculate_error_metrics(test_labels, label_predictions, model_name)\n",
    "\n",
    "    # in case these are the first results we want to store in that dataframe, we need to first create it\n",
    "    if metrics_collection is None:\n",
    "        metrics_collection = pd.DataFrame(columns=['model','RMSE','MAE','R2'])\n",
    " \n",
    "    metrics_collection = metrics_collection.append(metrics_dict, ignore_index=True )\n",
    "\n",
    "    #print_error_metrics(metrics_dict,model_name)\n",
    "\n",
    "    return metrics_collection\n",
    "\n",
    "# to time the model training we create a function for model training\n",
    "def train_model(x_train, y_train, model):\n",
    "    start_time = time.time()  \n",
    "    print(model)\n",
    "    model.fit(x_train,y_train)\n",
    "    print('Model training took: ', round((time.time() - start_time), 2), ' seconds')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline naive approach\n",
    "\n",
    "In order to determine, how well machine learning models perform on our dataset, we create some baseline results.\n",
    "One way to get baseline results is taking the median of y labels in the training dataset and use this as the prediction for all labels. Very naive, but not a realistic assumption.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the median training labels provides the predicted lable\n",
    "naive_prediction_value = y_train.median()\n",
    "naive_name = \"Naive median prediction\"\n",
    "print(naive_prediction_value)\n",
    "# the naive prediction value still needs to be repeated to fit with the features\n",
    "naive_predictions_val = pd.DataFrame([naive_prediction_value]* y_val.shape[0])\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,naive_predictions_val, naive_name), naive_name, 'validation')\n",
    "\n",
    "\n",
    "# and store the results on the test dataset for later model comparison\n",
    "naive_predictions_test = pd.DataFrame([naive_prediction_value]* y_test.shape[0])\n",
    "print_error_metrics(calculate_error_metrics(y_test,naive_predictions_test, naive_name), naive_name, 'test')\n",
    "metrics_collection = store_error_metrics(y_test,naive_predictions_test, naive_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Linear regression \n",
    "\n",
    "Another baseline approach for regression is linear regression. Compared to any of the following models it is still easy to compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = LinearRegression()\n",
    "linear_name = \"Linear Regression\"\n",
    "linear.fit(scaled_x_train, y_train)\n",
    "linear_predictions_val = linear.predict(scaled_x_val)\n",
    "\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,linear_predictions_val, linear_name), linear_name, 'validation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison\n",
    "linear_predictions_test = linear.predict(scaled_x_test)\n",
    "print_error_metrics(calculate_error_metrics(y_test,linear_predictions_test, linear_name), linear_name, 'test')\n",
    "metrics_collection = store_error_metrics(y_test,linear_predictions_test, linear_name, metrics_collection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost = GradientBoostingRegressor(n_estimators=30, learning_rate=0.1,verbose=1)\n",
    "grad_boost_name = \"Gradient Boosting Regressor\"\n",
    "grad_boost = train_model(x_train, y_train,grad_boost)\n",
    "grad_boost_predictions = grad_boost.predict(x_val)\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,grad_boost_predictions, grad_boost_name), grad_boost_name, 'validation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison, after we are done optimizing the parameters\n",
    "#grad_boost_predictions = grad_boost.predict(x_test)\n",
    "#print_error_metrics(calculate_error_metrics(y_test,grad_boost_predictions, grad_boost_name), grad_boost_name, 'test')\n",
    "#metrics_collection = store_error_metrics(y_test,grad_boost_predictions, grad_boost_name, metrics_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Regressor\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators=100,verbose=1)\n",
    "random_forest_name = \"Random Forest Regressor\"\n",
    "\n",
    "random_forest = train_model(x_train, y_train,random_forest)\n",
    "random_forest_predictions = random_forest.predict(x_val)\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,random_forest_predictions, random_forest_name), random_forest_name, 'validation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison, after we are done optimizing the parameters\n",
    "#random_forest_predictions = random_forest.predict(x_test)\n",
    "#print_error_metrics(calculate_error_metrics(y_test,random_forest_predictions, random_forest_name), random_forest_name, 'test')\n",
    "#metrics_collection = store_error_metrics(y_test,random_forest_predictions, random_forest_name, metrics_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's take a look at feature importances\n",
    "# create dataframe of feature importance from random forest model\n",
    "adf = pd.DataFrame(zip(x_train.columns, random_forest.feature_importances_), columns= ['name','importance'])\n",
    "# sort the dataframe to have highest ranking features first\n",
    "adf.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extra Trees Regressor\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees = ExtraTreesRegressor(n_estimators=30,verbose=1, random_state=random_seed)\n",
    "extra_trees_name = \"Extra Trees Regressor\"\n",
    "\n",
    "extra_trees = train_model(x_train, y_train,extra_trees)\n",
    "extra_trees_predictions = extra_trees.predict(x_val)\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,extra_trees_predictions, extra_trees_name), extra_trees_name, 'validation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison, after we are done optimizing the parameters\n",
    "#extra_trees_predictions = extra_trees.predict(x_test)\n",
    "#print_error_metrics(calculate_error_metrics(y_test,extra_trees_predictions, extra_trees_name), extra_trees_name,'test')\n",
    "#metrics_collection = store_error_metrics(y_test,extra_trees_predictions, extra_trees_name, metrics_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bagging Regressor\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingRegressor(n_estimators=30,verbose=1,random_state=random_seed )\n",
    "bagging_name = \"Bagging Regressor\"\n",
    "\n",
    "baggings = train_model(x_train, y_train,bagging)\n",
    "bagging_predictions = bagging.predict(x_val)\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,bagging_predictions, bagging_name), bagging_name, 'validation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison, after we are done optimizing the parameters\n",
    "#bagging_predictions = bagging.predict(x_test)\n",
    "#print_error_metrics(calculate_error_metrics(y_test,bagging_predictions, bagging_name), bagging_name, 'test')\n",
    "#metrics_collection = store_error_metrics(y_test,bagging_predictions, bagging_name, metrics_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. AdaBoost Regressor\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "* https://scikit-learn.org/stable/modules/ensemble.html#adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost = AdaBoostRegressor(n_estimators=30, learning_rate=1.0, loss='linear', random_state=random_seed)\n",
    "ada_boost_name = \"AdaBoost Regressor\"\n",
    "\n",
    "ada_boost = train_model(x_train, y_train,ada_boost)\n",
    "ada_boost_predictions = ada_boost.predict(x_val)\n",
    "\n",
    "# then we can get some performance metrics\n",
    "print_error_metrics(calculate_error_metrics(y_val,ada_boost_predictions, ada_boost_name), ada_boost_name, 'vaidation')\n",
    "\n",
    "# and store the results on the test dataset for later model comparison, after we are done optimizing the parameters\n",
    "#ada_boost_predictions = ada_boost.predict(x_test)\n",
    "#print_error_metrics(calculate_error_metrics(y_test,ada_boost_predictions, ada_boost_name), ada_boost_name, 'test')\n",
    "#metrics_collection = store_error_metrics(y_test,ada_boost_predictions, ada_boost_name, metrics_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model comparison\n",
    "\n",
    "Let's compare our models performance on the test dataset. Make sure to uncomment the lines to store the results in above cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_collection.sort_values(by=['RMSE'], ascending=False))\n",
    "\n",
    "# store comparison table \n",
    "metrics_collection.to_csv(metrics_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Task\n",
    "\n",
    "Study the scikit-learn documentation of one of the above used models and experiment with different hyperparameter values. Can you improve on the accuracy or make the training faster?\n",
    "Report the best results (on test set!) and mark down parameters used, so that others can reproduce the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: (removing most models from exercise notebook)\n",
    "Study the scikit-learn documentation for regression and find other models and experiment with different hyperparameter values. Can you improve on the accuracy or make the training faster?\n",
    "Report the best results (on test set!) and mark down model and parameters used, so that others can reproduce the results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
