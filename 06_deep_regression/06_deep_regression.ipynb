{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* have it without outputs on Github\n",
    "* more description to model building\n",
    "* reminder on parameters \n",
    "* explain numbers in model generation\n",
    "* add links where helpful\n",
    "* make sure to make it possible to go through this in 1:00\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Regression\n",
    "\n",
    "Reminder: We are within supervised learning (we have labels/targets that are real values) -> Regression\n",
    "\n",
    "Data and goal: In this notebook we read the zip code data produced by **02_vector_preparations** and create one deep learning model for\n",
    "predicting the average zip code income from population and spatial features. We will try to tune hyperparameters and finally assesses the models performance metrics on a previously unseen test dataset.\n",
    "\n",
    "Contents of this notebook:\n",
    "\n",
    "0. Prepare environment\n",
    "1. Reading the data\n",
    "2. Check for GPU\n",
    "3. Model definition\n",
    "4. Performance\n",
    "5. Comparison to shallow models\n",
    "6. Task\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "#plotting loss\n",
    "import matplotlib.pyplot as plt\n",
    "# error metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "# deep learning tools\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading the data\n",
    "### 1.1 Define input and output file paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get('USER')\n",
    "base_directory= f'/scratch/project_2002044/{username}/2022/GeoML'\n",
    "\n",
    "data_directory = os.path.join(base_directory,'data')\n",
    "\n",
    "#inputs\n",
    "preprocessed_data_directory = os.path.join(data_directory,'preprocessed_regression')\n",
    "train_dataset_name = os.path.join(preprocessed_data_directory,'scaled_train_zip_code_data.csv')\n",
    "test_dataset_name = os.path.join(preprocessed_data_directory,'scaled_test_zip_code_data.csv')\n",
    "val_dataset_name = os.path.join(preprocessed_data_directory,'scaled_val_zip_code_data.csv')\n",
    "train_label_name = os.path.join(preprocessed_data_directory,'train_income_labels.pkl')\n",
    "test_label_name = os.path.join(preprocessed_data_directory,'test_income_labels.pkl')\n",
    "val_label_name = os.path.join(preprocessed_data_directory,'val_income_labels.pkl')\n",
    "\n",
    "# outputs\n",
    "results_directory = os.path.join(data_directory,'regression_results')\n",
    "metrics_filename = os.path.join(results_directory,'shallow_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducible results when randomness is involved, we can set a random seed\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train, validation and test datasets\n",
    "x_train = pd.read_csv(train_dataset_name)\n",
    "x_val = pd.read_csv(val_dataset_name)\n",
    "y_train = pd.read_pickle(train_label_name)\n",
    "y_val = pd.read_pickle(val_label_name)\n",
    "x_test = pd.read_csv(test_dataset_name)\n",
    "y_test = pd.read_pickle(test_label_name)\n",
    "num_of_x_columns =  x_train.to_numpy().shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check for GPUs\n",
    "\n",
    "In this part of the course we do not yet need GPUs, the dataset and models used are sufficiently small, and training goes fast also on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGPUavailability():\n",
    "    device = tensorflow.config.list_physical_devices('GPU')\n",
    "    if device:\n",
    "        print(\"We have a GPU available!\")\n",
    "    else:\n",
    "        print(\"Sadly no GPU available. :( you have settle with a CPU. Good luck!\")\n",
    "\n",
    "checkGPUavailability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first layer with 64 perceptrons. Activation function is relu\n",
    "model.add(Dense(64, activation='relu', input_shape=(num_of_x_columns,)))\n",
    "\n",
    "# Add another layer with 64 perceptrons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# The last layer has to have only 1 perceptron as it is the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Setting optimizer and loss functions. Learning rate set to 0.001\n",
    "model.compile(optimizer=RMSprop(learning_rate=.001), loss='mse', metrics=['mae','mse'])\n",
    "print(model.summary())\n",
    "\n",
    "#Train the network with 1000 epochs and batch size of 64, store it into history, for loss plot\n",
    "history = model.fit(x_train, y_train, epochs=1000, shuffle=True, batch_size=64, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance\n",
    "\n",
    "After tuning the model based on the validation data, we can use the test set to report the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the performance of the model using previously unseen test dataset\n",
    "prediction = model.predict(x_test)\n",
    "r2 = r2_score(y_test, prediction)\n",
    "rmse = sqrt(mean_squared_error(y_test, prediction))\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(\"\\nMODEL ACCURACY METRICS WITH TEST DATASET: \\n\" +\n",
    "        \"\\t Root mean squared error: \"+ str(rmse) + \"\\n\" +\n",
    "        \"\\t Mean absolute error: \" + str(mae) + \"\\n\" +\n",
    "        \"\\t Coefficient of determination: \" + str(r2) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparison to shallow models and baseline \n",
    "\n",
    "Now we can print again the performance metrics for our models from the shallow regression exercises and see how the deep model is performing in comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shallow_metrics = pd.read_csv(metrics_filename)\n",
    "\n",
    "print(shallow_metrics.sort_values(by=['RMSE'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the tensorflow documentation and experiment with different hyperparameter values. Can you improve on the performance metrics?\n",
    "Report the best results (on test set!) and mark down parameters used, so that others can reproduce the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
