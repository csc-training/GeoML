{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**TODO:**\n",
    "* check all texts\n",
    "* fix comments\n",
    "* have it without outputs on Github\n",
    "* compare to results from shallow models\n",
    "* add task to build deeper models, add shape consinderations! Links to relevant pages.\n",
    "* more description to model building\n",
    "* reminder on parameters \n",
    "* train/test/val, use val for tuninig\n",
    "* make some tuning a task\n",
    "* Add note on CV\n",
    "* explain numbers in model generation\n",
    "* talk about engineered features\n",
    "* make sure to make it possible to go through this in 1:00\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Regression\n",
    "\n",
    "Data - prepared vector data\n",
    "\n",
    "Goal - use deep learning for predict the median income from zip code level population and spatial variables, assess the model accuracy with a test dataset, predicts the number to all zip codes and writes it to a geopackage\n",
    "\n",
    "Content of this notebook:\n",
    "\n",
    "0. Prepare environment\n",
    "1. Set paths\n",
    "2. Check for GPU\n",
    "3. Reading and preparing data \n",
    "4. Model definition\n",
    "5. Prediction and inference\n",
    "6. Comparison to shallow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from math import sqrt\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ.get('USER')\n",
    "base_directory= f'/scratch/project_2002044/{username}/2022/GeoML'\n",
    "\n",
    "data_directory = os.path.join(base_directory,'data')\n",
    "\n",
    "preprocessed_data_directory = os.path.join(data_directory,'preprocessed_regression')\n",
    "train_dataset_name = os.path.join(preprocessed_data_directory,'train_zip_code_data.csv')\n",
    "test_dataset_name = os.path.join(preprocessed_data_directory,'test_zip_code_data.csv')\n",
    "val_dataset_name = os.path.join(preprocessed_data_directory,'val_zip_code_data.csv')\n",
    "train_label_name = os.path.join(preprocessed_data_directory,'train_income_labels.pkl')\n",
    "test_label_name = os.path.join(preprocessed_data_directory,'test_income_labels.pkl')\n",
    "val_label_name = os.path.join(preprocessed_data_directory,'val_income_labels.pkl')\n",
    "\n",
    "\n",
    "metrics_filename = os.path.join(base_directory,'shallow_regression','shallow_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check for GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGPUavailability():\n",
    "    device = tensorflow.config.list_physical_devices('GPU')\n",
    "    if device:\n",
    "        print(\"We have a GPU available!\")\n",
    "    else:\n",
    "        print(\"Sadly no GPU available. :( you have settle with a CPU. Good luck!\")\n",
    "\n",
    "checkGPUavailability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Reading and preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and test datasets\n",
    "x_train = gpd.read_file(train_dataset_name)\n",
    "x_test = gpd.read_file(test_dataset_name)\n",
    "x_val = gpd.read_file(val_dataset_name)\n",
    "y_train = pd.read_pickle(train_label_name)\n",
    "y_test = pd.read_pickle(test_label_name)\n",
    "y_val = pd.read_pickle(val_label_name)\n",
    "num_of_x_columns =  x_train.to_numpy().shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add first layer with 64 perceptrons. Activation function is relu\n",
    "model.add(Dense(64, activation='relu', input_shape=(num_of_x_columns,)))\n",
    "\n",
    "# Add another layer with 64 perceptrons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# The last layer has to have only 1 perceptron as it is the output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Setting optimizer and loss functions. Learning rate set to 0.001\n",
    "model.compile(optimizer=RMSprop(learning_rate=.001), loss='mse', metrics=['mae','mse'])\n",
    "print(model.summary())\n",
    "\n",
    "#Train the network with 1000 epochs and batch size of 64\n",
    "model.fit(x_train, y_train, epochs=1000, shuffle=True, batch_size=64, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the performance of the model using test data\n",
    "prediction = model.predict(x_test)\n",
    "r2 = r2_score(y_test, prediction)\n",
    "rmse = sqrt(mean_squared_error(y_test, prediction))\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "\n",
    "print(\"\\nMODEL ACCURACY METRICS WITH TEST DATASET: \\n\" +\n",
    "        \"\\t Root mean squared error: \"+ str(rmse) + \"\\n\" +\n",
    "        \"\\t Mean absolute error: \" + str(mae) + \"\\n\" +\n",
    "        \"\\t Coefficient of determination: \" + str(r2) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison to shallow models and baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shallow_metrics = pd.read_csv(metrics_filename)\n",
    "\n",
    "print(shallow_metrics.sort_values(by=['RMSE'], ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
