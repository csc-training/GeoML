{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2. Raster data preparations\n",
    "\n",
    "In this exercise prepare the raster data for the classification excercises, where prediction of forest type is done based on a satellite image.\n",
    "\n",
    "The data used in these exercises is orinally from:\n",
    "* [Forest stands](https://www.metsaan.fi/paikkatietoaineistot) from Forest center (MetsÃ¤keskus). The exercise area is covered by 2 files: Uusimaa and Salo. These will be merged.\n",
    "* [Sentinel 2A satellite image](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2/data-products) (10m x 10m) from ESA. The data is provided with each band in separate file, so the bands will be merged.\n",
    "\n",
    "The goal of this exercise is to have 6 raster files:\n",
    "\n",
    "Images:\n",
    "1. Sentinel image rescaled to original reflections valus for training area\n",
    "1. Sentinel image rescaled to original reflections valus for prediction area\n",
    "\n",
    "Labels:\n",
    "1. Spruce forests as binary raster for training area\n",
    "1. Spruce forests as binary raster for prediction area\n",
    "1. Multi-class (spurce, pine, birch, other) forest raster for training area\n",
    "1. Multi-class (spurce, pine, birch, other) forest raster for prediction area\n",
    "\n",
    "In this exercise GDAL commandline commands are used, **not Python**. \n",
    "\n",
    "In Jupyter Notebooks, commandline commands start with **!** or **%**\n",
    "* **%** means the command will be ran so that the result persists for other code cells as well. You can navigate folders\n",
    "* **!** runs the command in a separate subprocess. This means that switching folders with `cd` would not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Download and unzip the data \n",
    "\n",
    "Using basic Linux commands:\n",
    "* `wget` downloads files from a URL\n",
    "* `unzip` \n",
    "\n",
    "See the generated files from the File browser in the left panel of Jupyter Labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_HOME='/home/jovyan/work/geocomputing/machineLearning/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {NOTEBOOK_HOME}\n",
    "%cd {NOTEBOOK_HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://a3s.fi/gis-courses/gis_ml/forest.zip\n",
    "! unzip -qu forest.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Satellite image preparations\n",
    "\n",
    "The original satellite image has each band as separate file. For **joining the bands** create first the false color composite as a virtual raster (.vrt) from the different bands.\n",
    "\n",
    "* **B08** = infrared\n",
    "* **B04** = red\n",
    "* **B03** = green\n",
    "\n",
    "Virtual raster is a handy concept for merging files. The created .vrt file is a small text file, that includes only links to the original files with data. Ofteb virtual raster file is used with data divided to mapsheets, but here all files are for the same mapsheet, so use the `-separate` option to create a file with 3 bands.\n",
    "\n",
    "TODO: remove PROJ_LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PROJ_LIB=/opt/conda/share/proj/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {NOTEBOOK_HOME}/forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdalbuildvrt T34VFM_20180829T100019.vrt \\\n",
    "    S2B_MSIL2A_20180829T100019_N0208_R122_T34VFM_20180829T184909.SAFE/GRANULE/L2A_T34VFM_A007727_20180829T100017/IMG_DATA/R10m/T34VFM_20180829T100019_B08_10m.jp2 \\\n",
    "    S2B_MSIL2A_20180829T100019_N0208_R122_T34VFM_20180829T184909.SAFE/GRANULE/L2A_T34VFM_A007727_20180829T100017/IMG_DATA/R10m/T34VFM_20180829T100019_B04_10m.jp2 \\\n",
    "    S2B_MSIL2A_20180829T100019_N0208_R122_T34VFM_20180829T184909.SAFE/GRANULE/L2A_T34VFM_A007727_20180829T100017/IMG_DATA/R10m/T34VFM_20180829T100019_B03_10m.jp2 \\\n",
    "    -separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally **clip and rescale** the image. In Sentinel images, the original values have been multiplied by 10 000 to get rid of decimals (0.0001 takes more disk space than 10 000). Machine learning models like to have values between 0 and 1, so let's scale the pixel values back to original: 0 to 10 000 -> 0 to 1.\n",
    "\n",
    "Options for the gdal_translate command:\n",
    "* `-projwin` defines the new bounding box (bbox) for data. Use smaller bbox for training the models and bigger bbox for predicting. Additionally use extra small bbox for shallow learning models to get results in reasonable time during course.\n",
    "* `-ot` image value type. Originally the data had integer type, chaning it to Float32.\n",
    "* `-scale` how to scale the value: 0 to 10 000 -> 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale and clip a little bit. This image will be used for CNN predictions.\n",
    "! gdal_translate T34VFM_20180829T100019.vrt T34VFM_20180829T100019_scaled.tif \\\n",
    "    -projwin 604500 6698500 677000 6640000 \\\n",
    "    -ot Float32 \\\n",
    "    -scale 0 10000 0 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip with medium bbox. This image will be used for training with all deep learning models and for predicting with fullyConnected DL model, and for clustering exercise.\n",
    "! gdal_translate T34VFM_20180829T100019_scaled.tif T34VFM_20180829T100019_clipped_scaled.tif \\\n",
    "    -projwin 614500 6668500 644500 6640500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip with small bbox. This image will be used for training and predicting with shallow learning models.\n",
    "! gdal_translate T34VFM_20180829T100019_scaled.tif T34VFM_20180829T100019_clipped_small_scaled.tif \\\n",
    "    -projwin 617500 6654000 624000 6647500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Forest stand preparations\n",
    "\n",
    "**Merge** the two GeoPackage files to one file, **clip** to predicting bbox and **change coordinte system** to the same as satellite image.\n",
    "\n",
    "Options for the ogr2ogr-command:\n",
    "* `stand` is the table name in original GeoPackage\n",
    "* `-f` output file format - GeoPackage.\n",
    "* `-t_srs` new coordinate system, EPSG:32634 is the code for UTM 34N\n",
    "* `-spat` prediction bbox in UTM 34N coordinates\n",
    "* `-spat_srs` EPSG code of the spat coodrinates - UTM 34N\n",
    "* `-append -update` - add the second dataset to the first one.\n",
    "\n",
    "This will take a moment, so please wait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ogr2ogr forest_clipped.gpkg MV_Salo.gpkg stand \\\n",
    "    -f GPKG \\\n",
    "    -t_srs epsg:32634 \\\n",
    "    -spat_srs epsg:32634 \\\n",
    "    -spat 604500 6698500 677000 6640000 \\\n",
    "    \n",
    "! ogr2ogr forest_clipped.gpkg MV_Uusimaa.gpkg stand \\\n",
    "    -f GPKG \\\n",
    "    -t_srs epsg:32634 \\\n",
    "    -spat_srs epsg:32634 \\\n",
    "    -spat 604500 6698500 677000 6640000 \\\n",
    "    -append -update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Rasterize** forest stand polygons and clip to the predicting bbox.\n",
    "\n",
    "Options for the gdal_translate command:\n",
    "* `-a` attribute to be used as the raster value\n",
    "* `-ot` raster data type\n",
    "* `-tr` pixel size\n",
    "* `-te` bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_rasterize forest_clipped.gpkg -l stand forest_species.tif \\\n",
    "    -a maintreespecies \\\n",
    "    -ot Byte \\\n",
    "    -tr 10 10 \\\n",
    "    -te 604500 6640000 677000 6698500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `gdalinfo -hist` for printing the histogram of the raster values. The histogram is at the very end of the long print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdalinfo forest_species.tif -hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram it can be seen, that the data has ~25 different tree species presented, but most of them have too few observations to be used for machine learning. So **reclassify** the forest main tree species to 4 classes to have enough data for each class:\n",
    "\n",
    "Pine (1), Spruce (2), Deciduous trees (3), No forest (0)\n",
    "\n",
    "Options for gdal_calc.py:\n",
    "* `--calc` - how to calculate the values of the new raster\n",
    "* `--NoDataValue` - what is the NoDataValue of the created raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_calc.py -A forest_species.tif --outfile=forest_species_reclassified.tif \\\n",
    "--calc=\"0*(A==0)+1*(A==1)+2*(A==2)+3*(A>=3)\" \\\n",
    "--NoDataValue=254 \\\n",
    "--quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdalinfo forest_species_reclassified.tif -hist -stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some excercises use only the spruce data for binary classification. \n",
    "Create a binary raster, with selecting only class 2 from the original rasterized image and recoding it to have value 1 in the raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_calc.py -A forest_species.tif --outfile=forest_spruce.tif \\\n",
    "--calc=\"0*(A<2)+0*(A>2)+1*(A==2)\" --quiet --NoDataValue=254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdalinfo forest_spruce.tif -hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clip** to training area bbox for both 4-class and 1-class datasets. Additionally clip for the shallow learning models with the smaller bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdal_translate forest_spruce.tif forest_spruce_clip.tif \\\n",
    "    -ot Byte \\\n",
    "    -projwin 614500 6668500 644500 6640500\n",
    "! gdal_translate forest_species_reclassified.tif forest_species_reclassified_clip.tif \\\n",
    "    -ot Byte \\\n",
    "    -projwin 614500 6668500 644500 6640500\n",
    "! gdal_translate forest_species_reclassified.tif forest_species_reclassified_clip_small.tif \\\n",
    "    -ot Byte \\\n",
    "    -projwin 617500 6654000 624000 6647500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gdalinfo forest_species_reclassified_clip.tif -hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the results with plotting:\n",
    "* Satellite image\n",
    "* Forest classification with 3 classes\n",
    "* Spruce forest\n",
    "* Forest classification with 3 classes histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "%matplotlib inline\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Help function to normalize band values and enhance contrast. Just like what QGIS does automatically\n",
    "def normalize(array):\n",
    "    min_percent = 2   # Low percentile\n",
    "    max_percent = 98  # High percentile\n",
    "    lo, hi = np.percentile(array, (min_percent, max_percent))\n",
    "    return (array - lo) / (hi - lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a subplot for 4 images \n",
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\n",
    "\n",
    "### Plot the sentinel image \n",
    "### The Sentinel image used for training  \n",
    "sentinel = rasterio.open(\"T34VFM_20180829T100019_clipped_scaled.tif\") \n",
    "#sentinel = rasterio.open(\"T34VFM_20180829T100019_clipped_small_scaled.tif\")\n",
    "\n",
    "### Read the bands separately and apply the normalize function to each of them to increase contrast\n",
    "nir, red, green = sentinel.read(1), sentinel.read(2), sentinel.read(3)\n",
    "nirn, redn, greenn = normalize(nir), normalize(red), normalize(green)\n",
    "stacked = np.dstack((nirn, redn, greenn))\n",
    "\n",
    "ax[0, 0].imshow(stacked)\n",
    "\n",
    "### The forest classification \n",
    "### Plot it a bit differently as it is not an RGB image\n",
    "forest_classes = rasterio.open(\"forest_species_reclassified_clip.tif\") \n",
    "#forest_classes = rasterio.open(\"forest_species_reclassified_clip_small.tif\")\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"orange\",\"darkgreen\",\"violet\"])\n",
    "show(forest_classes, ax=ax[0, 1], cmap=cmap, title='Forest classes')\n",
    "\n",
    "### Spruce forest \n",
    "forest_spruce = rasterio.open(\"forest_spruce_clip.tif\")\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"darkgreen\"])\n",
    "show(forest_spruce, ax=ax[1, 0], cmap=cmap, title='Spruce forests')\n",
    "\n",
    "### Plot the histogram of forest classification\n",
    "show_hist(forest_classes, ax=ax[1, 1], title=\"Forest classes histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try also plotting the datasets with smaller bbox with chaning the input file names for `sentinel` and `forest_classes`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
