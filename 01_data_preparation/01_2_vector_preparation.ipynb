{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector data for exercises\n",
    "\n",
    "In this course, we will use the vector dataset **Paavo**, which represents postal code area statistics collected by [Statistics Finland](https://www.stat.fi). Metadata description can be found on [Statistics Finland webpage](https://www.stat.fi/static/media/uploads/tup/paavo/paavo_kuvaus_en.pdf), see page 5 ff for field name descriptions.\n",
    "\n",
    "The variable descriptions of this dataset can be found here in Finnish and English\n",
    "* https://www.stat.fi/static/media/uploads/tup/paavo/paavo_lyhyt_kuvaus_2020_fi.pdf\n",
    "* https://www.stat.fi/static/media/uploads/tup/paavo/paavo_lyhyt_kuvaus_2020_en.pdf\n",
    "\n",
    "The dataset includes variables about each postcode area, describing:\n",
    "\n",
    "1. Population Structure (24 variables) HE\n",
    "2. Educational Structure (7 variables) KO\n",
    "3. Inhabitants' Disposable Monetary Income (7 variables) HR\n",
    "4. Size and Stage in Life of Households (15 variables) TE\n",
    "5. Households' Disposable Monetary Income (7 variables) TR\n",
    "6. Buildings and Dwellings (8 variables) RA\n",
    "7. Workplace Structure (26 variables) TP\n",
    "8. Main Type of Activity (9 variables) PT\n",
    "\n",
    "The overall goal of the exercises is to predict the median income for each zip code based on other variables/features of the dataset. \n",
    "To make this task worth an exercise, all variables/features of type HR are removed from the dataset.\n",
    "\n",
    "## Vector data preparations\n",
    "\n",
    "Content of this notebook:\n",
    "1. Data retrieval\n",
    "2. Data exploration\n",
    "3. Feature selection\n",
    "4. Feature scaling\n",
    "5. Feature encoding\n",
    "6. Store the results\n",
    "\n",
    "In this notebook we will download all the necessary datasets, clean up some features, scale all numerical values, join auxiliary\n",
    "data and encode text fields for machine learning purposes. We will save the result as geopackage.\n",
    "\n",
    "The goal of this exercise is to get the dataset ready for subsequent machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Load all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import zipfile\n",
    "import time\n",
    "# Data handling and plotting\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Geospatial data handling \n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, MultiPolygon, Polygon\n",
    "# Machine learning data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Download data from URL\n",
    "from urllib.request import urlretrieve\n",
    "# for saving the scaler, uncomment following:\n",
    "# from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data retrieval \n",
    "### 1.1 Create data directory if it does not yet exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['../data']\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download and unpack the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve('https://a3s.fi/gis-courses/gis_ml/paavo.zip', '../data/paavo.zip')\n",
    "\n",
    "with zipfile.ZipFile('../data/paavo.zip', 'r') as zip_file:\n",
    "    zip_file.extractall('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference for later: Getting data used in the course from Paituli\n",
    "\n",
    "# use wget (command line tool, therefore we need the !)\n",
    "!wget -r -l inf -N -np -nH -x -c --cut-dirs=4 ftp://ftp.funet.fi/index/geodata/tilastokeskus/paavo/2022/pno_tilasto_2022* -P ./data/vector/\n",
    "\n",
    "# creates dir any of dirs that does not exist and 2022 dir\n",
    "\n",
    "#The region for each post code area is retrieved from a spatial join with a regions dataset (SuomenMaankuntajako_2020_10k.shp).\n",
    "\n",
    "#TODO: check that this is the same as below!\n",
    "\n",
    "# get administrative borders\n",
    "\n",
    "#!wget -r -l inf -N -np -nH -x -c --cut-dirs=4 ftp://ftp.funet.fi/index/geodata/mml/hallintorajat_10k/2021-2022/ -P ./data/vector/\n",
    "# did not work?\n",
    "!wget -r -l inf -N -np -nH -x -c --cut-dirs=4 ftp://ftp.funet.fi/index/geodata/mml/hallintorajat_10k/2020/SuomenMaakuntajako_2020_10k* -P ./data/vector/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_code_shapefile = '../data/paavo/pno_tilasto_2020.shp'\n",
    "finnish_regions_shapefile = '../data/paavo/SuomenMaakuntajako_2020_10k.shp'\n",
    "output_file_path = '../data/paavo/zip_code_data_after_preparation.gpkg'\n",
    "scaler_path = '../data/paavo/zip_code_scaler.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data exploration\n",
    "### 2.1 Read the data into dataframe\n",
    "\n",
    "Read the zip code dataset into a geopandas dataframe **original_gdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the data from a shapefile to a geopandas dataframe\n",
    "original_gdf = gpd.read_file(zip_code_shapefile, encoding='utf-8')\n",
    "print(f\"Original dataframe size: {len(original_gdf.index)} zip codes with {len(original_gdf.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualization\n",
    "#### 2.2.1 Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot income feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting features against income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Map\n",
    "If plotting maps with matplotlib is not familiar. Here are some things you can play with\n",
    "* **figsize** - different height, width\n",
    "* **column** - try other zip code values\n",
    "* **cmap** - this is the color map, here are the possibile options https://matplotlib.org/3.3.1/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# set title for the full plot\n",
    "ax.set_title(\"Average income by zip code\", fontsize=25)\n",
    "# turn off all axes\n",
    "ax.set_axis_off()\n",
    "# plot the average income\n",
    "plot = original_gdf.plot(column='hr_mtu', ax=ax, legend=True, cmap=\"magma\")\n",
    "# set colorbar label\n",
    "cax = fig.get_axes()[1]\n",
    "cax.set_ylabel('Income in €');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_gdf.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['euref_x', 'euref_y', 'he_vakiy','he_3_6']\n",
    "\n",
    "for var in variables:\n",
    "    plt.figure() # Creating a rectangle (figure) for each plot\n",
    "    # Regression Plot also by default includes\n",
    "    # best-fitting regression line\n",
    "    # which can be turned off via `fit_reg=False`\n",
    "    sns.regplot(x=var, y='hr_mtu', data=original_gdf).set(title=f'Regression plot of {var} and average income');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: do only with subset of features\n",
    "\n",
    "correlations = original_gdf.corr()\n",
    "sns.heatmap(correlations, annot=True).set(title='Heatmap of Consumption Data - Pearson Correlations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature selection\n",
    "\n",
    "Let's drop some unnecessary rows and columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe size: 3026 zip codes with 109 columns\n",
      "Dataframe size after dropping no data rows: 2942 zip codes with 109 columns\n",
      "Dataframe size after dropping columns with string values and columns that make modeling too easy : 2942 zip codes with 101 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Drop all rows that have missing values or where average income is -1 (=not known) or 0\n",
    "original_gdf = original_gdf.dropna()    \n",
    "original_gdf = original_gdf[original_gdf[\"hr_mtu\"]>0].reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataframe size after dropping no data rows: {len(original_gdf.index)} zip codes with {len(original_gdf.columns)} columns\")\n",
    "\n",
    "### Remove some columns that are strings (namn, kunta = name of the municipality in Finnish and Swedish.)\n",
    "### or which might make the modeling too easy ('hr_mtu','hr_tuy','hr_pi_tul','hr_ke_tul','hr_hy_tul','hr_ovy')\n",
    "columns_to_be_removed_completely = ['namn','kunta','hr_ktu','hr_tuy','hr_pi_tul','hr_ke_tul','hr_hy_tul','hr_ovy']\n",
    "original_gdf = original_gdf.drop(columns_to_be_removed_completely,axis=1)\n",
    "\n",
    "print(f\"Dataframe size after dropping columns with string values and columns that make modeling too easy : {len(original_gdf.index)} zip codes with {len(original_gdf.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Scaling\n",
    "\n",
    "Feature Scaling is one of the most important data preparation steps. This is to avoid biasing algorithms that compute distances between features (e.g. like KNN, SVM and other non-treebased) towards numerically larger values. Feature scaling also helps the algorithm to train and converge faster.\n",
    "The most popoular scaling techniques are normalization and standardization.\n",
    "\n",
    "## 4.1 Normalization or min-max scaling \n",
    "\n",
    "* X_new = (X - X_min)/(X_max - X_min)\n",
    "* Used when features are of different scales, eg average size of household (te_takk) and number of inhabitants of a certain age class (he_x_y) \n",
    "* Scales the values into range [0,1] or [-1,1]\n",
    "* Data should not have any large outliers (data exploration!), as the rest of the data will be squashed into narrow range. -> Standardization is better option\n",
    "* Scikit-learn: [MinMaxScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)\n",
    "\n",
    "## 4.2 Standardization or Z-score normalization\n",
    "\n",
    "* X_new = (X - mean)/std\n",
    "* Used when \"zero mean and unit standard deviation\" needs to be ensured, we are standardizing to achieve equal variance of features\n",
    "* Not bound to specific range\n",
    "* less affected by outliers, as range is not set outliers will not have influence on the range of other values\n",
    "* \"1 implies that the value for that case is one standard deviation above the mean\"\n",
    "* Scikit-learn: [StandardScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/run/nvme/job_13750791/tmp/ipykernel_147760/1361996180.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Get list of all column headings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### List the column names that we don't want to be scaled, like zip-code and nimi (both regarded as string, cannot be scaled), median income (label) and geometry (cannot be scaled as is)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcol_names_no_scaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'postinumer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nimi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hr_mtu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "### Get list of all column headings\n",
    "all_columns = list(original_gdf.columns)\n",
    "\n",
    "### List the column names that we don't want to be scaled, like zip-code and nimi (both regarded as string, cannot be scaled), median income (label) and geometry (cannot be scaled as is)\n",
    "col_names_no_scaling = ['postinumer','nimi','hr_mtu','geometry']\n",
    "\n",
    "### List of column names we want to scale. (all columns minus those we don't want)\n",
    "col_names_to_scale = [column for column in all_columns if column not in col_names_no_scaling]\n",
    "\n",
    "### Subset the data for only those to-be scaled\n",
    "gdf = original_gdf[col_names_to_scale]\n",
    "\n",
    "### Apply a Scikit StandardScaler() or MinMaxScaler() for all the columns left in dataframe\n",
    "### You can also test both, store in different variables then\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "scaled_values_array = scaler.fit_transform(gdf)\n",
    "\n",
    "### You can save the scaler for later use. If there suddenly would be more zip codes in Finland, we should use the same scaler.\n",
    "# dump(scaler, scaler_path, compress=True)\n",
    "\n",
    "### Result is a numpy ndarray, which we pack back into geopandas dataframe\n",
    "gdf = pd.DataFrame(scaled_values_array)\n",
    "gdf.columns = col_names_to_scale\n",
    "\n",
    "### Join the non-scaled columns back with the the scaled columns by index\n",
    "scaled_gdf = original_gdf[col_names_no_scaling].join(gdf)\n",
    "scaled_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature encoding\n",
    "\n",
    "* Most Machine Learning algorithms cannot handle categorical features per se, they have to be converted to numerical values\n",
    "* Categorical features can be binary (True/False, 1/0), ordinal (low,medium,high) or nominal (monkey, donkey, tiger, penguin)\n",
    "\n",
    "This does not make any sense, but to practice, we can add region names to the post codes. One of the most-used encoding techniques is **one-hot encoding**. This means that instead of one column with different names, we create <number of unique values in column> new columns and fill then with 1/0. -> Same information content but numerical cells and no hierarchy (as we would get when simply assigning a numerical value to each string) -> also called \"dummy variables\"\n",
    "\n",
    "We use the pandas **get_dummies()** function for one-hot encoding. Scikit would also have a **OneHotEncoder()** transformer for this\n",
    "\n",
    "* More information on one-hot encoding https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding\n",
    "* It might not always be the best option. See other options https://towardsdatascience.com/stop-one-hot-encoding-your-categorical-variables-bbb0fba89809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Spatially join the region information to the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/CSC_CONTAINER/miniconda/envs/env1/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3472: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postinumer</th>\n",
       "      <th>nimi</th>\n",
       "      <th>hr_mtu</th>\n",
       "      <th>geometry</th>\n",
       "      <th>euref_x</th>\n",
       "      <th>euref_y</th>\n",
       "      <th>pinta_ala</th>\n",
       "      <th>he_vakiy</th>\n",
       "      <th>he_naiset</th>\n",
       "      <th>he_miehet</th>\n",
       "      <th>...</th>\n",
       "      <th>pt_vakiy</th>\n",
       "      <th>pt_tyoll</th>\n",
       "      <th>pt_tyott</th>\n",
       "      <th>pt_0_14</th>\n",
       "      <th>pt_opisk</th>\n",
       "      <th>pt_elakel</th>\n",
       "      <th>pt_muut</th>\n",
       "      <th>polygon_geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>NAMEFIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>99910</td>\n",
       "      <td>Kaamanen-Partakko</td>\n",
       "      <td>14958.0</td>\n",
       "      <td>POINT (503361.568 7678497.460)</td>\n",
       "      <td>0.652824</td>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.252585</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>POLYGON ((525777.302 7700650.894, 525850.693 7...</td>\n",
       "      <td>7</td>\n",
       "      <td>Lappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>99930</td>\n",
       "      <td>Sevettijärvi-Näätämö</td>\n",
       "      <td>16891.0</td>\n",
       "      <td>POINT (548890.739 7711836.158)</td>\n",
       "      <td>0.721755</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.375958</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>POLYGON ((574352.412 7709596.307, 573120.967 7...</td>\n",
       "      <td>7</td>\n",
       "      <td>Lappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>99950</td>\n",
       "      <td>Karigasniemi</td>\n",
       "      <td>20854.0</td>\n",
       "      <td>POINT (471402.146 7701544.993)</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.954666</td>\n",
       "      <td>0.254414</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.009425</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>POLYGON ((450197.347 7670193.165, 450054.015 7...</td>\n",
       "      <td>7</td>\n",
       "      <td>Lappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>99980</td>\n",
       "      <td>Utsjoki Keskus</td>\n",
       "      <td>20153.0</td>\n",
       "      <td>POINT (502680.384 7734902.492)</td>\n",
       "      <td>0.647052</td>\n",
       "      <td>0.981236</td>\n",
       "      <td>0.403985</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024915</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.041359</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>POLYGON ((519583.786 7768425.325, 519615.030 7...</td>\n",
       "      <td>7</td>\n",
       "      <td>Lappi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>99990</td>\n",
       "      <td>Nuorgam</td>\n",
       "      <td>21797.0</td>\n",
       "      <td>POINT (536019.915 7755327.036)</td>\n",
       "      <td>0.712512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109397</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.009440</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>POLYGON ((538700.093 7735625.716, 531298.591 7...</td>\n",
       "      <td>7</td>\n",
       "      <td>Lappi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     postinumer                  nimi   hr_mtu  \\\n",
       "2937      99910     Kaamanen-Partakko  14958.0   \n",
       "2938      99930  Sevettijärvi-Näätämö  16891.0   \n",
       "2939      99950          Karigasniemi  20854.0   \n",
       "2940      99980        Utsjoki Keskus  20153.0   \n",
       "2941      99990               Nuorgam  21797.0   \n",
       "\n",
       "                            geometry   euref_x   euref_y  pinta_ala  he_vakiy  \\\n",
       "2937  POINT (503361.568 7678497.460)  0.652824  0.934983   0.252585  0.005023   \n",
       "2938  POINT (548890.739 7711836.158)  0.721755  0.963719   0.375958  0.007240   \n",
       "2939  POINT (471402.146 7701544.993)  0.605400  0.954666   0.254414  0.010010   \n",
       "2940  POINT (502680.384 7734902.492)  0.647052  0.981236   0.403985  0.024194   \n",
       "2941  POINT (536019.915 7755327.036)  0.712512  1.000000   0.109397  0.006760   \n",
       "\n",
       "      he_naiset  he_miehet  ...  pt_vakiy  pt_tyoll  pt_tyott   pt_0_14  \\\n",
       "2937   0.004094   0.006178  ...  0.005127  0.003996  0.005880  0.002072   \n",
       "2938   0.005732   0.008857  ...  0.007596  0.007239  0.011307  0.004375   \n",
       "2939   0.008120   0.011835  ...  0.010255  0.009425  0.004071  0.013125   \n",
       "2940   0.021290   0.026051  ...  0.024915  0.018474  0.010855  0.020032   \n",
       "2941   0.006619   0.006922  ...  0.007292  0.007088  0.004975  0.009440   \n",
       "\n",
       "      pt_opisk  pt_elakel   pt_muut  \\\n",
       "2937  0.002740   0.010694  0.003094   \n",
       "2938  0.001245   0.011637  0.003094   \n",
       "2939  0.003487   0.012581  0.005569   \n",
       "2940  0.008966   0.041359  0.015470   \n",
       "2941  0.002989   0.007548  0.006188   \n",
       "\n",
       "                                       polygon_geometry  index_right  NAMEFIN  \n",
       "2937  POLYGON ((525777.302 7700650.894, 525850.693 7...            7    Lappi  \n",
       "2938  POLYGON ((574352.412 7709596.307, 573120.967 7...            7    Lappi  \n",
       "2939  POLYGON ((450197.347 7670193.165, 450054.015 7...            7    Lappi  \n",
       "2940  POLYGON ((519583.786 7768425.325, 519615.030 7...            7    Lappi  \n",
       "2941  POLYGON ((538700.093 7735625.716, 531298.591 7...            7    Lappi  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read the regions shapefile and choose only the name of the region and its geometry\n",
    "finnish_regions_gdf = gpd.read_file(finnish_regions_shapefile)\n",
    "finnish_regions_gdf = finnish_regions_gdf[['NAMEFIN','geometry']]\n",
    "\n",
    "### A function we use to return centroid point geometry from a zip code polygon\n",
    "def returnPointGeometryFromXY(polygon_geometry):\n",
    "    ## Calculate x and y of the centroid\n",
    "    centroid_x,centroid_y = polygon_geometry.centroid.x,polygon_geometry.centroid.y\n",
    "    ## Create a shapely Point geometry of the x and y coords\n",
    "    point_geometry = Point(centroid_x,centroid_y)\n",
    "    return point_geometry\n",
    "\n",
    "### Stash the polygon geometry to another column as we are going to overwrite the 'geometry' with centroid geometry\n",
    "scaled_gdf['polygon_geometry'] = scaled_gdf['geometry']\n",
    "\n",
    "### We will be joining the region name to zip codes according to the zip code centroid. \n",
    "### This calls the function above and returns centroid to every row\n",
    "scaled_gdf[\"geometry\"] = scaled_gdf['geometry'].apply(returnPointGeometryFromXY)\n",
    "\n",
    "### Spatially join the region name to the zip codes using the centroid of zip codes and region polygons\n",
    "scaled_gdf = gpd.sjoin(scaled_gdf,finnish_regions_gdf,how='inner',op='intersects')\n",
    "scaled_gdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 One-hot encode the region name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size after adding region name: 2942 zip codes with 120 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postinumer</th>\n",
       "      <th>nimi</th>\n",
       "      <th>hr_mtu</th>\n",
       "      <th>geometry</th>\n",
       "      <th>euref_x</th>\n",
       "      <th>euref_y</th>\n",
       "      <th>pinta_ala</th>\n",
       "      <th>he_vakiy</th>\n",
       "      <th>he_naiset</th>\n",
       "      <th>he_miehet</th>\n",
       "      <th>...</th>\n",
       "      <th>Lappi</th>\n",
       "      <th>Pirkanmaa</th>\n",
       "      <th>Pohjanmaa</th>\n",
       "      <th>Pohjois-Karjala</th>\n",
       "      <th>Pohjois-Pohjanmaa</th>\n",
       "      <th>Pohjois-Savo</th>\n",
       "      <th>Päijät-Häme</th>\n",
       "      <th>Satakunta</th>\n",
       "      <th>Uusimaa</th>\n",
       "      <th>Varsinais-Suomi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>99910</td>\n",
       "      <td>Kaamanen-Partakko</td>\n",
       "      <td>14958.0</td>\n",
       "      <td>MULTIPOLYGON (((525777.302 7700650.894, 525850...</td>\n",
       "      <td>0.652824</td>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.252585</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>99930</td>\n",
       "      <td>Sevettijärvi-Näätämö</td>\n",
       "      <td>16891.0</td>\n",
       "      <td>MULTIPOLYGON (((574352.412 7709596.307, 573120...</td>\n",
       "      <td>0.721755</td>\n",
       "      <td>0.963719</td>\n",
       "      <td>0.375958</td>\n",
       "      <td>0.007240</td>\n",
       "      <td>0.005732</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>99950</td>\n",
       "      <td>Karigasniemi</td>\n",
       "      <td>20854.0</td>\n",
       "      <td>MULTIPOLYGON (((450197.347 7670193.165, 450054...</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.954666</td>\n",
       "      <td>0.254414</td>\n",
       "      <td>0.010010</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>99980</td>\n",
       "      <td>Utsjoki Keskus</td>\n",
       "      <td>20153.0</td>\n",
       "      <td>MULTIPOLYGON (((519583.786 7768425.325, 519615...</td>\n",
       "      <td>0.647052</td>\n",
       "      <td>0.981236</td>\n",
       "      <td>0.403985</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>99990</td>\n",
       "      <td>Nuorgam</td>\n",
       "      <td>21797.0</td>\n",
       "      <td>MULTIPOLYGON (((538700.093 7735625.716, 531298...</td>\n",
       "      <td>0.712512</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.109397</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     postinumer                  nimi   hr_mtu  \\\n",
       "2937      99910     Kaamanen-Partakko  14958.0   \n",
       "2938      99930  Sevettijärvi-Näätämö  16891.0   \n",
       "2939      99950          Karigasniemi  20854.0   \n",
       "2940      99980        Utsjoki Keskus  20153.0   \n",
       "2941      99990               Nuorgam  21797.0   \n",
       "\n",
       "                                               geometry   euref_x   euref_y  \\\n",
       "2937  MULTIPOLYGON (((525777.302 7700650.894, 525850...  0.652824  0.934983   \n",
       "2938  MULTIPOLYGON (((574352.412 7709596.307, 573120...  0.721755  0.963719   \n",
       "2939  MULTIPOLYGON (((450197.347 7670193.165, 450054...  0.605400  0.954666   \n",
       "2940  MULTIPOLYGON (((519583.786 7768425.325, 519615...  0.647052  0.981236   \n",
       "2941  MULTIPOLYGON (((538700.093 7735625.716, 531298...  0.712512  1.000000   \n",
       "\n",
       "      pinta_ala  he_vakiy  he_naiset  he_miehet  ...  Lappi  Pirkanmaa  \\\n",
       "2937   0.252585  0.005023   0.004094   0.006178  ...      1          0   \n",
       "2938   0.375958  0.007240   0.005732   0.008857  ...      1          0   \n",
       "2939   0.254414  0.010010   0.008120   0.011835  ...      1          0   \n",
       "2940   0.403985  0.024194   0.021290   0.026051  ...      1          0   \n",
       "2941   0.109397  0.006760   0.006619   0.006922  ...      1          0   \n",
       "\n",
       "      Pohjanmaa  Pohjois-Karjala  Pohjois-Pohjanmaa  Pohjois-Savo  \\\n",
       "2937          0                0                  0             0   \n",
       "2938          0                0                  0             0   \n",
       "2939          0                0                  0             0   \n",
       "2940          0                0                  0             0   \n",
       "2941          0                0                  0             0   \n",
       "\n",
       "      Päijät-Häme  Satakunta  Uusimaa  Varsinais-Suomi  \n",
       "2937            0          0        0                0  \n",
       "2938            0          0        0                0  \n",
       "2939            0          0        0                0  \n",
       "2940            0          0        0                0  \n",
       "2941            0          0        0                0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Switch the polygon geometry back to the 'geometry' field and drop uselesss columns\n",
    "scaled_gdf['geometry'] = scaled_gdf['polygon_geometry']\n",
    "scaled_gdf.drop(['index_right','polygon_geometry'],axis=1, inplace=True)\n",
    "\n",
    "### Encode the region name with the One-hot encoding (= in pandas, dummy encoding)\n",
    "encoded_gdf = pd.get_dummies(scaled_gdf['NAMEFIN'])\n",
    "\n",
    "### Join scaled gdf and encoded gdf together\n",
    "scaled_and_encoded_gdf = scaled_gdf.join(encoded_gdf).drop('NAMEFIN',axis=1)\n",
    "\n",
    "### The resulting dataframe has Polygon and Multipolygon geometries. \n",
    "### This upcasts the polygons to multipolygon format so all of them have the same format\n",
    "scaled_and_encoded_gdf[\"geometry\"] = [MultiPolygon([feature]) if type(feature) == Polygon else feature for feature in scaled_and_encoded_gdf[\"geometry\"]]\n",
    "print(\"Dataframe size after adding region name: \" + str(len(scaled_and_encoded_gdf.index))+ \" zip codes with \" + str(len(scaled_and_encoded_gdf.columns)) + \" columns\")\n",
    "\n",
    "### Print the tail of the dataframe\n",
    "scaled_and_encoded_gdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/CSC_CONTAINER/miniconda/envs/env1/lib/python3.9/site-packages/geopandas/io/file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "### Write the prepared zipcode dataset to a geopackage\n",
    "scaled_and_encoded_gdf.to_file(output_file_path, driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
