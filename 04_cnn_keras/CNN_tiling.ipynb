{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ee3ee-630a-476f-90bf-51265f492713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raster data preparations for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64132581-1c4f-4b26-9eb0-54b5e8a56984",
   "metadata": {},
   "source": [
    "In this exercise, the raster data for the CNN classification excercis is prepared.\n",
    "\n",
    "Before starting with this exercise, the [general raster data preparations exercise](raster_preparations.ipynb) must be done or alternatively download the data and labels images as input data, code provided below. Also the data requirements listed in previous exercise are valid here.\n",
    "\n",
    "Satellite images are usually too big for CNN models as such, se we need to tile them to smaller pieces. In our example the original image is 5000 x 5000 pixels, and the model 512 x 512 pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca3010-c9ab-40b0-a516-2a6b6afd5d50",
   "metadata": {},
   "source": [
    "## Data inputs\n",
    "\n",
    "* Coordinate system: Finnish ETRS-TM35FIN, EPSG:3067\n",
    "* Resolution: 20m\n",
    "* BBOX: 200000, 6700000, 300000, 6800000\n",
    "\n",
    "#### Labels\n",
    "\n",
    "* Binary classification raster: 1 - forest, 0 - everything else.\n",
    "* Multiclass classification raster: 1 - forest, 2 - fields, 3 - water, 4 - urban, 0 - everything else.\n",
    "\n",
    "#### Data image\n",
    "\n",
    "* Sentinel2 mosaic, we include data from 2 different dates (May and July), to have more data values. Final dataset has 8 bands based on bands: 2, 3, 4 and 8 on dates: 2021-05-11 and 2021-07-21, reflection values scaled to [0 ... 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fedbc0d-c43a-4010-afb5-b93670df4968",
   "metadata": {},
   "source": [
    "## Data processing results\n",
    "\n",
    "The goal of this exercise is to have 4 sets of raster tiles.\n",
    "\n",
    "#### Label tiles for training\n",
    "For better augmentation we make the training tiles bigger (1024 x 1024) than the model, so that at training time a random clip can be done. Use also overlapping tiling scheme to get more training data.\n",
    "\n",
    "* Binary classification tiles. Tile size: 1024 x 1024, overlap 512.\n",
    "* Multiclass classification tiles. Tile size: 1024 x 1024, overlap 512.\n",
    "\n",
    "#### Data tiles for training\n",
    "* Sentinel2 mosaic tiles. Tile size: 1024 x 1024, overlap 512.\n",
    "\n",
    "#### Data tiles for predicting\n",
    "* Sentinel2 mosaic tiles. Tile size: 512 x 512 (same size as model). No overlap.\n",
    "\n",
    "#### Tar-files for training\n",
    "1. Binary classification tiles + Sentinel2 mosaic tiles.\n",
    "2. Multiclass classification tiles + Sentinel2 mosaic tiles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abb202-5477-47d4-be34-e2faf1890a94",
   "metadata": {},
   "source": [
    "## Data processing main steps\n",
    "(Download input data if needed.)\n",
    "1. Create folders for tiles\n",
    "2. Tile the input images as specified above.\n",
    "3. GDAL creates also smaller then specified tiles on image edges, so remove too small tiles.\n",
    "4. Create a .tar-package of tiles for binary and multiclass training. Tar-package is easy to move to the GPU-node for faster reads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8f4a8-0480-4f80-a537-5c2892b05584",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2302559-6b0c-4d77-9899-c3b443aadd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import rasterio\n",
    "import tarfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dcc19b-c56d-46c9-94aa-8eda4979895e",
   "metadata": {},
   "source": [
    "Set file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17760e7b-ed5c-4836-8a96-903e8b4bb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"..\"\n",
    "\n",
    "image_url = 'https://a3s.fi/gis-courses/gis_ml/image.tif'\n",
    "binary_classification_url = 'https://a3s.fi/gis-courses/gis_ml/labels_forest.tif'\n",
    "multiclass_classification_url = 'https://a3s.fi/gis-courses/gis_ml/labels_multiclass.tif'\n",
    "\n",
    "image_file = os.path.join(base_folder, 'image.tif')\n",
    "binary_classification_file = os.path.join(base_folder, 'labels_forest.tif')\n",
    "multiclass_classification_file = os.path.join(base_folder, 'labels_multiclass.tif')\n",
    "cnn_folder = os.path.join(base_folder, '04_cnn_keras') \n",
    "\n",
    "trainingTileSize = 1024\n",
    "modelTileSize = 512\n",
    "\n",
    "imageTilesForTrainingFolder = os.path.join(cnn_folder, ('imageTiles_' + str(trainingTileSize)))\n",
    "labelTilesForBinaryFolder = os.path.join(cnn_folder, ('binaryLabelTiles_' + str(trainingTileSize)))\n",
    "labelTilesForMultiClassFolder = os.path.join(cnn_folder, ('multiclassLabelTiles_' + str(trainingTileSize)))\n",
    "imageTilesForPredictionFolder = os.path.join(cnn_folder, ('imageTiles_' + str(modelTileSize)))\n",
    "\n",
    "trainingBinaryTarFile = os.path.join(cnn_folder,('trainingTilesBinary_' + str(trainingTileSize) + '.tar'))\n",
    "trainingMultiClassTarFile = os.path.join(cnn_folder,('trainingTilesMulti_' + str(trainingTileSize) + '.tar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fa037-a1f6-4e20-8716-ba64c684af07",
   "metadata": {},
   "source": [
    "(Download input data if needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23765c7e-f379-4907-8b4d-5786a3117197",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(image_file):\n",
    "    urllib.request.urlretrieve(image_url, image_file)\n",
    "    \n",
    "if not os.path.exists(binary_classification_file):\n",
    "    urllib.request.urlretrieve(binary_classification_url, binary_classification_file)    \n",
    "    \n",
    "if not os.path.exists(multiclass_classification_file):\n",
    "    urllib.request.urlretrieve(multiclass_classification_url, multiclass_classification_file)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f52ce-1c54-4d91-ae77-1811dd35d581",
   "metadata": {},
   "source": [
    "1. Create folders for tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f06d703-28d2-4ef6-ac62-f3302cf088e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(imageTilesForTrainingFolder):\n",
    "    os.makedirs(imageTilesForTrainingFolder)\n",
    "    \n",
    "if not os.path.exists(labelTilesForBinaryFolder):\n",
    "    os.makedirs(labelTilesForBinaryFolder)\n",
    "    \n",
    "if not os.path.exists(labelTilesForMultiClassFolder):\n",
    "    os.makedirs(labelTilesForMultiClassFolder)\n",
    "    \n",
    "if not os.path.exists(imageTilesForPredictionFolder):\n",
    "    os.makedirs(imageTilesForPredictionFolder)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df38220-2c1a-4e76-b62d-13316e38a6dc",
   "metadata": {},
   "source": [
    "2. Tile the input images as specified above, using GDAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3f5c740-446b-4998-b9f0-d7e1e6c6292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "!gdal_retile.py -ps {trainingTileSize} {trainingTileSize} -overlap {modelTileSize} -targetDir {imageTilesForTrainingFolder} {image_file}\n",
    "# -ps - tile size in pixels\n",
    "# -overlap - overlap of tiles in pixels\n",
    "# -targetDir - the directory of output tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a54ade6-30a1-4430-a01b-dc8856f1d173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# Tile the satellite image for predicting with the bigger bbox and model size tiles.\n",
    "!gdal_retile.py -ps {modelTileSize} {modelTileSize} -targetDir {imageTilesForPredictionFolder} {image_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "581594b1-a06f-4d75-aeb6-6b59623dc173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# # Tile the labels with the same setting as the image. Only spurce for CNN\n",
    "!gdal_retile.py -ps {trainingTileSize} {trainingTileSize} -overlap {modelTileSize} -targetDir {labelTilesForBinaryFolder} {binary_classification_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "227fdebf-df57-4614-ae42-27fea0b6fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    }
   ],
   "source": [
    "# # Labels for multiclass CNN\n",
    "!gdal_retile.py -ps {trainingTileSize} {trainingTileSize} -overlap {modelTileSize} -targetDir {labelTilesForMultiClassFolder} {multiclass_classification_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74647ff8-dade-4c74-aa3e-0ec0de1648cb",
   "metadata": {},
   "source": [
    "3. GDAL creates also smaller then specified tiles on image edges, so remove too small tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2529221-2025-472d-a9fb-f0127f30917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_too_small_tiles(folder, size):\n",
    "    all_tiles = glob.glob(folder+\"/*.tif\")\n",
    "    for tile in all_tiles:\n",
    "        with rasterio.open(tile) as src:\n",
    "            if src.meta[\"height\"] != size:\n",
    "                print(tile)\n",
    "                os.remove(tile)\n",
    "                continue\n",
    "            if src.meta[\"width\"] != size:\n",
    "                print(tile)\n",
    "                os.remove(tile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23354eb9-4c9d-431a-9465-cab23a8f66ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too small tiles, that are removed:\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_6_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_2.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_4.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_1.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_7_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_8_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_3.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_5.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_7.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_6.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_9_8.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_5_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_3_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_4_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_2_9.tif\n",
      "../04_cnn_keras/binaryLabelTiles_1024/labels_forest_1_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_6.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_3.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_5_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_2_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_4_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_8_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_4.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_6_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_7_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_1_9.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_1.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_2.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_5.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_8.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_9_7.tif\n",
      "../04_cnn_keras/multiclassLabelTiles_1024/labels_multiclass_3_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_6_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_7_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_8_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_1_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_7.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_8.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_1.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_4_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_5.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_2.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_5_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_3_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_3.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_4.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_2_9.tif\n",
      "../04_cnn_keras/imageTiles_1024/image_9_6.tif\n",
      "../04_cnn_keras/imageTiles_512/image_05_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_04_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_09.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_01.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_06.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_03.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_08.tif\n",
      "../04_cnn_keras/imageTiles_512/image_06_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_01_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_07.tif\n",
      "../04_cnn_keras/imageTiles_512/image_09_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_07_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_03_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_02.tif\n",
      "../04_cnn_keras/imageTiles_512/image_02_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_08_10.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_05.tif\n",
      "../04_cnn_keras/imageTiles_512/image_10_04.tif\n"
     ]
    }
   ],
   "source": [
    "# CNN model requires at least 512x512 size of images, so the remove the files from right and bottom edge, that are too small.\n",
    "print('Too small tiles, that are removed:')\n",
    "remove_too_small_tiles(labelTilesForBinaryFolder, trainingTileSize)\n",
    "remove_too_small_tiles(labelTilesForMultiClassFolder, trainingTileSize)\n",
    "remove_too_small_tiles(imageTilesForTrainingFolder, trainingTileSize)\n",
    "remove_too_small_tiles(imageTilesForPredictionFolder, modelTileSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df96f63-3585-4c61-8fd5-5aa2e940a97b",
   "metadata": {},
   "source": [
    "4. Create a .tar-package of tiles for binary and multiclass training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25293f13-a15a-4c9c-8f90-99e0e26a4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tarfile(output_filename, source_dirs):\n",
    "    if os.path.exists(output_filename):\n",
    "        os.remove(output_filename)\n",
    "    with tarfile.open(output_filename, \"w\") as tar:\n",
    "        for folder in source_dirs:\n",
    "            tar.add(folder, arcname=os.path.basename(folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79b6b2-e653-449b-aa2a-14ef0413f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_tarfile(trainingBinaryTarFile, [imageTilesForTrainingFolder, labelTilesForBinaryFolder])\n",
    "make_tarfile(trainingMultiClassTarFile, [imageTilesForTrainingFolder, labelTilesForMultiClassFolder])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
